{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from scipy.signal import find_peaks\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import BirdsongDataset\n",
    "from src.network import AutoEncoderClassifier\n",
    "from src.utils import GetSortedSpeciesCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(str(Path.cwd().parent.parent.joinpath('setting', 'config.ini')))\n",
    "\n",
    "WIN_LEN = config['Window'].getint('Length')\n",
    "HOP_LEN = WIN_LEN * (1 - config['Window'].getfloat('Overlap'))\n",
    "TARGET_SPECIES = GetSortedSpeciesCode(Path.cwd().parent.parent.joinpath('setting', 'SPECIES.csv'))\n",
    "THRESHOLD = config['Application']['Threshold'].split(',')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device(f'cuda:{config[\"Model\"][\"Classifier_Device\"]}')\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbabilityResults(weightPath:Path):\n",
    "  model = AutoEncoderClassifier(len(TARGET_SPECIES)).to(DEVICE)\n",
    "  model.load_state_dict(torch.load(weightPath, map_location=torch.device(DEVICE)))\n",
    "\n",
    "  allDataloader = DataLoader(\n",
    "    BirdsongDataset(Path.cwd().parent.parent.joinpath('data', 'tmp', 'oneMin-test.csv'), False, False),\n",
    "    batch_size=4, shuffle=False, num_workers=4, pin_memory=True\n",
    "  )\n",
    "\n",
    "  predicts = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for _, (inputs, _) in tqdm(enumerate(allDataloader), total=len(allDataloader)):\n",
    "      inputs = inputs.to(DEVICE)\n",
    "      outputs = F.sigmoid(model(inputs))\n",
    "      predicts.extend(outputs.cpu().numpy())\n",
    "  predicts = np.array(np.reshape(predicts, (-1, len(TARGET_SPECIES))))\n",
    "  return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFileLabels(filePaths:Path):\n",
    "  \"\"\"\n",
    "    計算人工標記檔案每一物種標籤數\n",
    "  \"\"\"\n",
    "  df = pd.DataFrame(columns=['file']+TARGET_SPECIES)\n",
    "  for i, filePath in enumerate(filePaths):\n",
    "    df.loc[i, 'file'] = Path('NrAudio', f'{filePath.stem}.wav')\n",
    "    \n",
    "    labelDF = pd.read_csv(filePath, sep='\\t', names=['st', 'et', 'species'])\n",
    "    labelDF['species'] = labelDF['species'].str.upper().replace(' ', '')\n",
    "    labelDF = labelDF[labelDF['species'].str.contains('-S+', regex=True, na=False)]\n",
    "    labelDF.reset_index(drop=True, inplace=True)\n",
    "    labelDF['species'] = labelDF['species'].apply(lambda x: str(x).split('-')[0])\n",
    "    labelDF = labelDF[labelDF['species'].apply(lambda x: x in TARGET_SPECIES)] # Select TARGET_SPECIES\n",
    "\n",
    "    if labelDF.empty:\n",
    "      continue\n",
    "    \n",
    "    vcDict = labelDF['species'].value_counts()\n",
    "    for k, v in vcDict.items():\n",
    "      df.loc[i, k] = v\n",
    "\n",
    "  df.fillna(0, inplace=True)\n",
    "  df.set_index('file', inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'Label').glob('*.txt'))\n",
    "\n",
    "chunk = pd.read_csv(Path.cwd().parent.parent.joinpath('data', 'ae-dataset.csv'), header=0, chunksize=100000)\n",
    "aeDF = pd.concat(chunk)\n",
    "aeDF['file'] = aeDF['file'].apply(lambda x: Path(x).stem)\n",
    "aeDF = aeDF[aeDF['file'].isin([p.stem for p in labelPaths])]\n",
    "aeDF['file'] = aeDF['file'].apply(lambda x: Path('NrAudio', f'{x}.wav'))\n",
    "aeDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', 'oneMin-test.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightPath = Path.cwd().parent.parent.joinpath('model', 'AEClassifier20220626.pth')   # Select model weight manually\n",
    "predicts = getProbabilityResults(weightPath)\n",
    "predicts = np.array(np.reshape(predicts, (-1, len(TARGET_SPECIES))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupData = pd.DataFrame(predicts, index=aeDF['file'], columns=TARGET_SPECIES).groupby(by='file')\n",
    "predictsDF = pd.DataFrame(0, index=aeDF['file'].unique(), columns=TARGET_SPECIES)\n",
    "for file, group in tqdm(groupData):\n",
    "  for i, sp in enumerate(TARGET_SPECIES):\n",
    "    peaks, _ = find_peaks(group[sp], height=float(THRESHOLD[i]))\n",
    "    predictsDF.loc[file, sp] = len(peaks)\n",
    "\n",
    "actualsDF = countFileLabels(labelPaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for i in range(len(labelPaths)):\n",
    "  setList = list(zip(actualsDF.iloc[i, :].to_list(), predictsDF.iloc[i, :].to_list()))\n",
    "  count.append([element for subList in setList for element in subList])\n",
    "\n",
    "countDFCol = pd.MultiIndex.from_product([TARGET_SPECIES, ['actual', 'predict']])\n",
    "countDF = pd.DataFrame.from_records(count, index=[p.stem for p in labelPaths], columns=countDFCol)\n",
    "countDF.to_csv(Path.cwd().parent.parent.joinpath('report', 'table', 'songCount.csv'), header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "802908908370ccb42dc2a7ac32386db1a5400a9392b38929d32ff89e4b8f01c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
