{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from scipy.signal import find_peaks\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import BirdsongDataset\n",
    "from src.network import AutoEncoderClassifer\n",
    "from src.utils import GetSortedSpeciesCode, SegmentWithSlidingWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(str(Path.cwd().parent.parent.joinpath('setting', 'config.ini')))\n",
    "WIN_LEN = config['Window'].getint('Length')\n",
    "HOP_LEN = WIN_LEN * (1 - config['Window'].getfloat('Overlap'))\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device(f'cuda:{config[\"Model\"][\"Classifier_Device\"]}')\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "\n",
    "TARGET_SPECIES = GetSortedSpeciesCode(Path.cwd().parent.parent.joinpath('setting', 'SPECIES.csv'))\n",
    "THRESHOLD = config['Application']['Threshold'].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTmpCSV(audioPath:Path):\n",
    "  df = pd.DataFrame(columns=['file', 'start time', 'end time'])\n",
    "  source = sf.SoundFile(audioPath)\n",
    "  df['start time'] = SegmentWithSlidingWindow(source.frames/source.samplerate, WIN_LEN, HOP_LEN)\n",
    "  df['end time'] = df['start time'] + WIN_LEN\n",
    "  df['file'] = Path('NrAudio', f'{audioPath.stem}.wav')\n",
    "  df.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', 'single-test.csv'), header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbabilityResults(weightPath:Path):\n",
    "  model = AutoEncoderClassifer(len(TARGET_SPECIES)).to(DEVICE)\n",
    "  model.load_state_dict(torch.load(weightPath, map_location=torch.device(DEVICE)))\n",
    "\n",
    "  allDataloader = DataLoader(\n",
    "    BirdsongDataset(Path.cwd().parent.parent.joinpath('data', 'tmp', 'single-test.csv'), False, False),\n",
    "    batch_size=4, shuffle=False, num_workers=4, pin_memory=True\n",
    "  )\n",
    "\n",
    "  predicts = []\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for _, (inputs, _) in tqdm(enumerate(allDataloader), total=len(allDataloader)):\n",
    "      inputs = inputs.to(DEVICE)\n",
    "      outputs = F.sigmoid(model(inputs))\n",
    "      predicts.extend(outputs.cpu().numpy())\n",
    "  predicts = np.array(np.reshape(predicts, (-1, len(TARGET_SPECIES))))\n",
    "  return predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAutoLabelDataset(filename, allPeaks):\n",
    "  if Path.cwd().parent.parent.joinpath('data', 'auto-dataset.csv').exists():\n",
    "    df = pd.read_csv(Path.cwd().parent.parent.joinpath('data', 'auto-dataset.csv'), header=0)\n",
    "  else:\n",
    "    df = pd.DataFrame(columns=['file', 'start time', 'end time', 'label'])\n",
    "  \n",
    "  for i, vs in allPeaks.items():\n",
    "    df = pd.concat(\n",
    "      [df, pd.DataFrame({\n",
    "        'file': Path('NrAudio', filename),\n",
    "        'start time': np.around(i * HOP_LEN, decimals=6),\n",
    "        'end time': np.around(i * HOP_LEN + WIN_LEN, decimals=6),\n",
    "        'label': ','.join(vs)\n",
    "      }, index=[0])], ignore_index=True\n",
    "    )\n",
    "  df.drop_duplicates(subset=['file', 'start time', 'end time'])\n",
    "  df.to_csv(Path.cwd().parent.parent.joinpath('data', 'auto-dataset.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrAudioPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'NrAudio').glob('GW01*.wav'))\n",
    "\n",
    "for nrAudioPath in tqdm(nrAudioPaths):\n",
    "  ## 1. Create temporary csv file for model input\n",
    "  createTmpCSV(nrAudioPath)\n",
    "  ## 2. Input to the model\n",
    "  weightPath = Path.cwd().parent.parent.joinpath('model', 'AEClassifer20220626.pth')    # Select model weight manually\n",
    "  predicts = getProbabilityResults(weightPath)\n",
    "  ## 3. Find peaks for species\n",
    "  allPaeks = collections.defaultdict(list)\n",
    "  for i, sp in enumerate(TARGET_SPECIES):\n",
    "    peaks, _ = find_peaks(predicts[:, i], height=THRESHOLD[i])\n",
    "    for p in peaks:\n",
    "      allPaeks[p].append(sp)\n",
    "  ## 4. Generate an concat label to auto-label dataset\n",
    "  generateAutoLabelDataset(nrAudioPath.stem, allPaeks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "802908908370ccb42dc2a7ac32386db1a5400a9392b38929d32ff89e4b8f01c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
