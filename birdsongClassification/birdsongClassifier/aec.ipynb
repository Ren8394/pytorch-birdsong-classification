{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-encoder Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
    "from torch.utils.data import DataLoader\n",
    "from tkinter import *\n",
    "from tkinter.filedialog import askopenfilename\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.dataset import BirdsongDataset\n",
    "from src.network import AutoEncoderClassifier\n",
    "from src.utils import CalculateImbalanceWeight, GetSortedSpeciesCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(str(Path.cwd().parent.parent.joinpath('setting', 'config.ini')))\n",
    "\n",
    "EPOCHS = config['Model'].getint('Epochs')\n",
    "BATCH_SIZE = config['Model'].getint('BatchSize')\n",
    "LEARNING_RATE = config['Model'].getfloat('LearningRate')\n",
    "EARLY_STOP = config['Model'].getint('EarlyStop')\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device(f'cuda:{config[\"Model\"][\"Classifier_Device\"]}')\n",
    "  torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "  DEVICE = torch.device('cpu')\n",
    "\n",
    "TARGET_SPECIES = GetSortedSpeciesCode(Path.cwd().parent.parent.joinpath('setting', 'SPECIES.csv'))\n",
    "IMBALANCE_WEIGHT = CalculateImbalanceWeight(\n",
    "  Path.cwd().parent.parent.joinpath('data', 'tmp', 'aec-train.csv'), weightType='ens'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderWeightPath = Path.cwd().parent.parent.joinpath('model', 'AE20220706_encoder.pth')  # Manual change weight path\n",
    "modelWeightPath = Path.cwd().parent.parent.joinpath('model', f'AEClassifier{datetime.now().strftime(\"%Y%m%d\")}.pth')\n",
    "\n",
    "model = AutoEncoderClassifier(numberOfClass=len(TARGET_SPECIES)).to(DEVICE)               # @AutoEncoderClassifier need @numberOfClass as input\n",
    "model.encoder.load_state_dict(torch.load(encoderWeightPath, map_location=DEVICE))\n",
    "for param in model.encoder.parameters():\n",
    "  param.requires_grad = False\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss(IMBALANCE_WEIGHT).to(DEVICE)                             # Use binary cross entropy with log as loss fuction\n",
    "                                                                                          # We use log to avoid unstable situation\n",
    "bestLoss = np.Inf\n",
    "earlyCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aecTrainDataloader = DataLoader(\n",
    "  BirdsongDataset(Path.cwd().parent.parent.joinpath('data', 'tmp', 'aec-train.csv'), needAugment=True, needLabel=True),\n",
    "  batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "aecValidateDataloader = DataLoader(\n",
    "  BirdsongDataset(Path.cwd().parent.parent.joinpath('data', 'tmp', 'aec-validate.csv'), needAugment=False, needLabel=True),\n",
    "  batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(EPOCHS)):\n",
    "  # Train\n",
    "  model.train()\n",
    "  trainingLoss = 0.0\n",
    "  for _, (inputs, labels) in tqdm(enumerate(aecTrainDataloader), total=len(aecTrainDataloader)):\n",
    "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    trainingLoss += loss.item()\n",
    "  trainingLoss /= len(aecTrainDataloader)\n",
    "\n",
    "  # Validate \n",
    "  model.eval()\n",
    "  validationLoss = 0.0\n",
    "  with torch.no_grad():\n",
    "    for _, (inputs, labels) in tqdm(enumerate(aecValidateDataloader), total=len(aecValidateDataloader)):\n",
    "      inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "      validationLoss += loss.item()\n",
    "  validationLoss /= len(aecValidateDataloader)\n",
    "\n",
    "  # Check loss\n",
    "  if validationLoss < bestLoss:\n",
    "    bestLoss = validationLoss\n",
    "    earlyCount = 0\n",
    "    torch.save(model.state_dict(), modelWeightPath)\n",
    "  else:\n",
    "    earlyCount += 1\n",
    "    if earlyCount >= EARLY_STOP:\n",
    "      break\n",
    "\n",
    "  # Print results\n",
    "  print(f\"\"\"\n",
    "    >> [{epoch + 1} / {EPOCHS}] ~~ ~~ AutoEncodeClassifer\n",
    "    >> {\"Best V Loss :\":>16} {bestLoss} + [{earlyCount}]\n",
    "    >> {\"Current T Loss :\":>16} {trainingLoss:6f}\n",
    "    >> {\"Current V Loss :\":>16} {validationLoss:6f}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "root.withdraw()\n",
    "modelWeightPath = askopenfilename(\n",
    "  title='Choose The File Of Model Weight', \n",
    "  initialdir=Path.cwd().parent.parent.joinpath('model')\n",
    ")\n",
    "root.destroy()\n",
    "\n",
    "model = AutoEncoderClassifier(numberOfClass=len(TARGET_SPECIES)).to(DEVICE)\n",
    "model.load_state_dict(torch.load(modelWeightPath, map_location=torch.device(DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aecTestDataloader = DataLoader(\n",
    "  BirdsongDataset(Path.cwd().parent.parent.joinpath('data', 'tmp', 'aec-test.csv'), needAugment=False, needLabel=True),\n",
    "  batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts, actuals = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for _, (inputs, labels) in tqdm(enumerate(aecTestDataloader), total=len(aecTestDataloader)):\n",
    "    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "    outputs = F.sigmoid(model(inputs))\n",
    "    predicts.extend(outputs.cpu().numpy())\n",
    "    actuals.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statisticDFIndex = pd.MultiIndex.from_product([TARGET_SPECIES, ['precision', 'recall', 'f0.5', 'f1', 'f2']])\n",
    "thresList = np.around(np.arange(0, 1, 0.01), decimals=2)\n",
    "statisticDF = pd.DataFrame(columns=thresList, index=statisticDFIndex)\n",
    "\n",
    "# @predicts and @actuals in a 1-D array, thus we need to reshape it to 2-D array, which each column is our @TARGET_SPECIES\n",
    "trueLabel = np.array(np.reshape(actuals, (-1, len(TARGET_SPECIES))), dtype=int)\n",
    "# Result will be formated in four-decimal\n",
    "for thres in thresList:\n",
    "  predictLabel = np.array(np.reshape(predicts, (-1, len(TARGET_SPECIES)))>= thres, dtype=int)\n",
    "  for i, sp in enumerate(TARGET_SPECIES):\n",
    "    # Precision calculation\n",
    "    statisticDF.loc[(sp, 'precision'), thres] = np.round(\n",
    "      precision_score(y_pred=predictLabel[:, i], y_true=trueLabel[:, i], zero_division=0), decimals=4\n",
    "    )\n",
    "    # Recall calculation\n",
    "    statisticDF.loc[(sp, 'recall'), thres] = np.round(\n",
    "      recall_score(y_pred=predictLabel[:, i], y_true=trueLabel[:, i], zero_division=0), decimals=4\n",
    "    )\n",
    "    # F0.5\n",
    "    statisticDF.loc[(sp, 'f0.5'), thres] = np.round(\n",
    "      fbeta_score(y_pred=predictLabel[:, i], y_true=trueLabel[:, i], zero_division=0, beta=0.5), decimals=4\n",
    "    )\n",
    "    # F1\n",
    "    statisticDF.loc[(sp, 'f1'), thres] = np.round(\n",
    "      fbeta_score(y_pred=predictLabel[:, i], y_true=trueLabel[:, i], zero_division=0, beta=1), decimals=4\n",
    "    )\n",
    "    # F2\n",
    "    statisticDF.loc[(sp, 'f2'), thres] = np.round(\n",
    "      fbeta_score(y_pred=predictLabel[:, i], y_true=trueLabel[:, i], zero_division=0, beta=2), decimals=4\n",
    "    )\n",
    "\n",
    "# If there is na in our results, replace it with 0\n",
    "statisticDF.fillna(0, inplace=True)\n",
    "statisticDF.T.to_csv(\n",
    "  Path.cwd().parent.parent.joinpath('report', 'table', f'{modelWeightPath.stem}.csv'), header=True, index=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "802908908370ccb42dc2a7ac32386db1a5400a9392b38929d32ff89e4b8f01c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
