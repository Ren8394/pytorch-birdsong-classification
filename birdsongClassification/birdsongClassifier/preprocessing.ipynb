{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2 as pg\n",
    "import soundfile as sf\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from sqlalchemy import create_engine\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from src.utils import SegmentWithSlidingWindow, GetSortedSpeciesCode, OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(str(Path.cwd().parent.parent.joinpath('setting', 'config.ini')))\n",
    "\n",
    "WIN_LEN = config['Window'].getint('Length')\n",
    "HOP_LEN = WIN_LEN * (1 - config['Window'].getfloat('Overlap'))\n",
    "TARGET_SPECIES = GetSortedSpeciesCode(Path.cwd().parent.parent.joinpath('setting', 'SPECIES.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_str = 'postgresql://postgres:Tfri23039978@localhost:5432/tfri'\n",
    "db = create_engine(conn_str)\n",
    "conn = db.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducing noise\n",
    "\n",
    "1. 取得所有未降噪音檔路徑\n",
    "2. 讀取未降噪音檔, 標準化音檔, 最後使用 [noisereduce](https://github.com/timsainb/noisereduce) 進行降噪 \n",
    "3. 輸出降噪後檔案於 \"_pwd/../data/NrAudio/_\", wav 格式\n",
    "4. 刪除未降噪檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduceNoise(filePaths:Path, remove:bool=True):\n",
    "  for filePath in tqdm(filePaths):\n",
    "    audio, sr = librosa.load(str(filePath), sr=None)\n",
    "    audio = librosa.util.normalize(audio.T)\n",
    "    nrAudio = nr.reduce_noise(y=audio, sr=sr, use_tqdm=True)\n",
    "    sf.write(\n",
    "      Path.cwd().parent.parent.joinpath('data', 'NrAudio', f'{filePath.stem}.wav'),\n",
    "      data=nrAudio, samplerate=sr, subtype='PCM_24'\n",
    "    )\n",
    "    if remove:\n",
    "      Path.unlink(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawAudioPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'Audio').glob('*.wav'))\n",
    "openAudioPaths = \\\n",
    "  sorted(Path.cwd().parent.parent.joinpath('data', 'OpenSource').glob('*.mp3')) + \\\n",
    "  sorted(Path.cwd().parent.parent.joinpath('data', 'OpenSource').glob('*.wav'))\n",
    "\n",
    "reduceNoise(rawAudioPaths, remove=True)   # reduce noise and delete raw files\n",
    "reduceNoise(openAudioPaths, remove=False) # reduce noise and keep raw files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Auto-encoder Classifier dataset\n",
    "\n",
    "將人工標記檔案細切，以取得乾淨、較高品質資料\n",
    "\n",
    "1. 去除非屬song-type之鳥音\n",
    "2. 將剩餘鳥音以適當演算法進行切割\n",
    "   ```\n",
    "    < Before >\n",
    "    Start  End  Label\n",
    "    -------------------\n",
    "    1      3    [1,0,0]\n",
    "    2      4    [0,1,0]\n",
    "    5      9    [1,0,0]\n",
    "    6      8    [0,1,0]\n",
    "    7      10   [0,0,1]\n",
    "\n",
    "    < After >\n",
    "    Start  End  Label\n",
    "    -------------------\n",
    "    1      2    [1,0,0]\n",
    "    2      3    [1,1,0]\n",
    "    3      4    [0,1,0]\n",
    "    5      6    [1,0,0]\n",
    "    6      7    [1,1,0]\n",
    "    7      8    [1,1,1]\n",
    "    8      9    [1,0,1]\n",
    "    9      10   [0,0,1]\n",
    "   ```\n",
    "3. 切除後鳥音如大於 WIN_LEN 則進行滑移視窗處理, 如否則不處理\n",
    "4. 保留資料時長大於等於0.5秒標記"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentSignalLabel(df:pd.DataFrame):\n",
    "  records = []\n",
    "  labels = []\n",
    "  for i, x in df.iterrows():\n",
    "    records.append([x['start_time'], 'L', i])\n",
    "    records.append([x['end_time'], 'R', i])\n",
    "    labels.append(x['species'])\n",
    "  # Sort by time\n",
    "  records = sorted(records)\n",
    "\n",
    "  overlap = []\n",
    "  results = []\n",
    "  for j, record in enumerate(records):\n",
    "    if record[1] == 'L':\n",
    "      if overlap: # Overlap means get L but previous L' aren't finished by its R'\n",
    "        labelList = [label for k, label in enumerate(labels) if k in overlap]\n",
    "        labelList = set(labelList)  # Use set to remove identical label\n",
    "        results.append([records[j-1][0], record[0], labelList])\n",
    "        overlap.append(record[2])\n",
    "      else:\n",
    "        overlap.append(record[2])\n",
    "    else:\n",
    "      labelList = [label for k, label in enumerate(labels) if k in overlap]\n",
    "      labelList = set(labelList)\n",
    "      results.append([records[j-1][0], record[0], labelList])\n",
    "      overlap.remove(record[2])\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateClassifierDataset(filePaths:Path, outputFilename:str):\n",
    "  df = pd.DataFrame(columns=['file', 'start_time', 'end_time', 'species'])\n",
    "  for filePath in tqdm(filePaths):\n",
    "    # Preporcess\n",
    "    singleDF = pd.read_csv(filePath, sep='\\t', names=['start_time', 'end_time', 'species'])\n",
    "    singleDF = singleDF[singleDF['start_time'] != '\\\\']\n",
    "    singleDF['species'] = singleDF['species'].str.upper().replace(' ', '')\n",
    "    singleDF = singleDF[singleDF['species'].str.contains('-S+', regex=True, na=False)]\n",
    "    singleDF.reset_index(drop=True, inplace=True)\n",
    "    singleDF['species'] = singleDF['species'].apply(lambda x: str(x).split('-')[0])\n",
    "    \n",
    "    if singleDF.empty:\n",
    "      continue\n",
    "\n",
    "    # Segment signal interval\n",
    "    segmentedDF = pd.DataFrame(segmentSignalLabel(singleDF), columns=['start_time', 'end_time', 'species'])\n",
    "    source = sf.SoundFile(Path.cwd().parent.parent.joinpath('data', 'NrAudio', f'{filePath.stem}.wav'))\n",
    "    segmentedDF['end_time'] = segmentedDF['end_time'].apply(lambda x: min(x, source.frames / source.samplerate))\n",
    "    segmentedDF['file'] = str(Path('NrAudio', f'{filePath.stem}.wav'))\n",
    "    segmentedDF = segmentedDF[['file', 'start_time', 'end_time', 'species']]\n",
    "\n",
    "    # Sliding window\n",
    "    shortDF = segmentedDF[segmentedDF['end_time'] - segmentedDF['start_time'] <= WIN_LEN]   # Duration less and equal than {WIN_LEN}\n",
    "    longDF = segmentedDF[segmentedDF['end_time'] - segmentedDF['start_time'] > WIN_LEN]     # Duration greater than {WIN_LEN}\n",
    "    for _, x in longDF.iterrows():\n",
    "      st, et = x['start_time'], x['end_time'] - WIN_LEN\n",
    "      slidingWindow = []\n",
    "      while st <= et:\n",
    "        slidingWindow.append([x['file'], np.around(st, decimals=6), np.around(st + WIN_LEN, decimals=6), x['species']])\n",
    "        st += HOP_LEN\n",
    "      shortDF = pd.concat(\n",
    "        [shortDF, pd.DataFrame(slidingWindow, columns=['file', 'start_time', 'end_time', 'species'])],\n",
    "        ignore_index=True\n",
    "      )\n",
    "\n",
    "    # Filter\n",
    "    shortDF = shortDF[shortDF['end_time'] - shortDF['start_time'] > 0.5]    # Only duration > 0.5 are accept\n",
    "    shortDF.sort_values(by=['file', 'start_time', 'end_time'], inplace=True)\n",
    "    shortDF['species'] = shortDF['species'].apply(lambda x: sorted(x))\n",
    "\n",
    "    # Concatenate\n",
    "    df = pd.concat([df, shortDF], ignore_index=True)\n",
    "  \n",
    "  # Save results\n",
    "  df['species'] = df['species'].apply(lambda x: ','.join(x))\n",
    "  df.to_csv(Path.cwd().parent.parent.joinpath('data', f'{outputFilename}.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfLabelPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'Label').glob('*.txt'))\n",
    "openLabelPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'OpenSource').glob('*.txt'))\n",
    "\n",
    "generateClassifierDataset(selfLabelPaths, 'manual-dataset')\n",
    "generateClassifierDataset(openLabelPaths, 'opensource-dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Auto-encoder dataset\n",
    "\n",
    "以所有已降噪音訊製作 auto-encoder 資料集\n",
    "\n",
    "1. 讀取音檔並取得其播放長度\n",
    "2. 以滑移視窗的方式切割出資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateAEDataset(filePaths:Path):\n",
    "  ae = []\n",
    "  for filePath in tqdm(filePaths):\n",
    "    source = sf.SoundFile(filePath)\n",
    "    stList = SegmentWithSlidingWindow(\n",
    "      length=source.frames / source.samplerate,\n",
    "      windowLength=WIN_LEN, hopLength=HOP_LEN\n",
    "    )\n",
    "    for st in stList:\n",
    "      ae.append([str(Path('NrAudio', f'{filePath.stem}.wav')), st, st + WIN_LEN])\n",
    "  \n",
    "  df = pd.DataFrame(ae, columns=['file', 'start_time', 'end_time'])\n",
    "  df.to_csv(Path.cwd().parent.parent.joinpath('data', f'ae-dataset.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrAudioPaths = sorted(Path.cwd().parent.parent.joinpath('data', 'NrAudio').glob('*.wav'))\n",
    "generateAEDataset(nrAudioPaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separating dataset for model\n",
    "\n",
    "共 3 個資料集, 第一個為自動標記資料集, 下一個為人工標記資料集, 最後是開源資料集。  \n",
    "目前將所有資料集丟入 Model 進行訓練, 唯開源資料集不進入 Model 測試\n",
    "\n",
    "1. 決定切割比例\n",
    "2. 將 label 以 onehot 模式表示\n",
    "3. 切割資料集為 train, validate, test 三群 (Note: auto-encoder 無 test)\n",
    "4. 儲存資料進暫時資料夾 \"_pwd/../data/tmp/_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierRatio = (0.8, 0.1, 0.1)\n",
    "autoencoderRatio = (0.9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterTarget(df:pd.DataFrame):\n",
    "  df['species'] = df['species'].apply(lambda x: [l for l in x.split(',') if l in TARGET_SPECIES])\n",
    "  df['onehot'] = df['species'].apply(lambda x: pd.NA if len(x) == 0 else OneHotEncoding(x, TARGET_SPECIES))\n",
    "  df.dropna(inplace=True)\n",
    "  # df[TARGET_SPECIES] = pd.DataFrame(df['code'].tolist(), index=df.index)  # Trans 'code' to specific species\n",
    "  df = df[['file', 'start_time', 'end_time', 'onehot']]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoDF = filterTarget(pd.read_csv(Path.cwd().parent.parent.joinpath('data', f'auto-dataset.csv'), header=0))\n",
    "selfDF = filterTarget(pd.read_csv(Path.cwd().parent.parent.joinpath('data', f'manual-dataset.csv'), header=0))\n",
    "openDF = filterTarget(pd.read_csv(Path.cwd().parent.parent.joinpath('data', f'opensource-dataset.csv'), header=0))\n",
    "\n",
    "# Split <train, validate, test> = <0.8 : 0.1 : 0.1>\n",
    "# np.split |------------|--------------|----------|\n",
    "#          0   train   0.8  validate  0.9  test  1.0\n",
    "#          |     8      :      1       :     1    |\n",
    "# 8 : 1 : 1 -> cut point 0.8 * total length, and 0.9 * total length\n",
    "\n",
    "autoTrainDF, autoValidateDF, autoTestDF = np.split(autoDF.sample(frac=1), \n",
    "  [int(classifierRatio[0] * len(autoDF)), int((classifierRatio[0] + classifierRatio[1]) * len(autoDF))]\n",
    ")\n",
    "selfTrainDF, selfValidateDF, selfTestDF = np.split(selfDF.sample(frac=1), \n",
    "  [int(classifierRatio[0] * len(selfDF)), int((classifierRatio[0] + classifierRatio[1]) * len(selfDF))]\n",
    ")\n",
    "aecTrainDF = pd.concat([autoTrainDF, selfTrainDF, openDF], ignore_index=True)\n",
    "aecValidateDF = pd.concat([autoValidateDF, selfValidateDF], ignore_index=True)\n",
    "aecTestDF = pd.concat([autoTestDF, selfTestDF], ignore_index=True)\n",
    "aecTrainDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', f'aec-train.csv'), header=True, index=False)\n",
    "aecValidateDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', f'aec-validate.csv'), header=True, index=False)\n",
    "aecTestDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', f'aec-test.csv'), header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeDF = pd.read_csv(Path.cwd().parent.parent.joinpath('data', f'ae-dataset.csv'), header=0)\n",
    "aeTrainDF, aeValidateDF = np.split(aeDF.sample(frac=1), [int(autoencoderRatio[0] * len(aeDF))])\n",
    "aeTrainDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', f'ae-train.csv'), header=True, index=False)\n",
    "aeValidateDF.to_csv(Path.cwd().parent.parent.joinpath('data', 'tmp', f'ae-validate.csv'), header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pytorch_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "802908908370ccb42dc2a7ac32386db1a5400a9392b38929d32ff89e4b8f01c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
